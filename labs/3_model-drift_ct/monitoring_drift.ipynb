{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 : Questions on AZ ML\n",
    "\n",
    "- Question 1 : Please give a definition of the cloud and 3 examples of public cloud providers\n",
    "\n",
    "- Question 2 : What is the difference between public cloud and private cloud ?\n",
    "\n",
    "- Question 3 : What are resources group for in Azure ?\n",
    "\n",
    "- Question 4 : In the lab, describe the role of the MLClient\n",
    "\n",
    "- Question 5 : Why do we choose the \"AzureML-tensorflow-2.12-cuda11@latest\" environment for our training job ?\n",
    "\n",
    "- Question 6 : Please describe the difference between a model registration, a model deployment and an endpoint\n",
    "\n",
    "- Question 7 : What is the purpose of the scoring script for the model deployment ?\n",
    "\n",
    "- Question 8 : What is the difference between real time inference and batch inference ?\n",
    "\n",
    "- Question 9 : What does the locust library do ?\n",
    "\n",
    "- Question 10 : At the end of the lab, is it more important to delete the endpoints, the model registration or the deployments ?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 : Detecting Drift\n",
    "\n",
    "In this tutorial, we will look at 2 senarios where a model's performance is severely hurt by model drift. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can try this\n",
    "\n",
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the requirements.txt did not work, you can execute this cell\n",
    "\n",
    "import sys\n",
    "import site\n",
    "import subprocess\n",
    "site_path = ! python -c \"import site; print(site.getsitepackages()[0])\"\n",
    "site_path = site_path[0]\n",
    "\n",
    "if site_path not in sys.path:\n",
    "    sys.path.append(site_path)\n",
    "    \n",
    "!{sys.executable} -m pip install numpy pandas scipy\n",
    "!{sys.executable} -m pip install keras\n",
    "!{sys.executable} -m pip install plotly\n",
    "!{sys.executable} -m pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import numpy as np\n",
    "if not hasattr(np, 'bool'):\n",
    "    np.bool = bool\n",
    "from keras.datasets import mnist\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import ks_2samp\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Senario 1: Recognizing the digit 1\n",
    "\n",
    "In this senario, you are a data scientist from the fictitious country of Driftistan. You are tasked with creating a model that recognizes from a handwritten drawing of a digit if a 1 is written or not. **It is currently year 2 and the people of Driftistan only use 3 digits** : 0, 1 and 2. \n",
    "\n",
    "To simulate this, we will take an extract of the MNIST dataset and train our model on a subset containing the digits 0, 1 and 2. The model used is a simple random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
    "\n",
    "\n",
    "figure=px.imshow(train_X[0], color_continuous_scale='gray', title=\"first digit of the database\")\n",
    "\n",
    "figure.show()\n",
    "\n",
    "# If this does not work, uncomment this following line\n",
    "#figure.write_html(\"my_plot.html\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very little preprocessing is needed here. First, the database is filtered according to the labels (only labels 0, 1 and 2 are kept for now). Then, the training data is scaled and reshaped to fit the input format of the classifier. Finally, the labels are changed so that for all digits other than 1, the label is 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This max digit is the maximum digit that the people of Driftistan know\n",
    "max_digit=2\n",
    "\n",
    "# the list of indices where the label is 0,1 or 2\n",
    "indices=np.where(train_y<max_digit+1)\n",
    "\n",
    "X=train_X[indices]/256\n",
    "X=X.reshape((X.shape[0],X.shape[1]*X.shape[2]))\n",
    "y=train_y[indices]\n",
    "\n",
    "# The label 0 and 1 stay the same, only the label 2 changes for now\n",
    "y[y==2]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this integer determines the size of the training input data\n",
    "train_size=1000\n",
    "\n",
    "\n",
    "train_indices=np.random.choice(X.shape[0], train_size, replace=False)\n",
    "\n",
    "\n",
    "X=X[train_indices]\n",
    "y=y[train_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier chosen here is a random forest classifier. A random forest is a supervised machine learning algorithme based on decision trees. Each decision tree is a graphical representation of binary nodes that are trained to make decisions on a random subset of the data. The choices from each decision tree are then aggregated with a simple majority vote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(max_depth=2)\n",
    "\n",
    "# training the data\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this integer determines the size of the test data. It is constant to have a more homogenous accuracy calculation every year\n",
    "test_size=300\n",
    "\n",
    "indices=np.where(test_y<max_digit+1)\n",
    "\n",
    "\n",
    "test=test_X[indices]/256\n",
    "test=test.reshape((test.shape[0],test.shape[1]*test.shape[2]))\n",
    "true_y=test_y[indices]\n",
    "\n",
    "# The label 0 and 1 stay the same, only the label 2 changes for now\n",
    "true_y[true_y==2]=0\n",
    "\n",
    "test_indices=np.random.choice(test.shape[0], test_size, replace=False)\n",
    "\n",
    "test=test[test_indices]\n",
    "true_y=true_y[test_indices]\n",
    "\n",
    "pred_y=clf.predict(test)\n",
    "accuracy=accuracy_score(true_y, pred_y)\n",
    "print(\"baseline accuracy is : \",accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over time, the people of Driftistan gradually learn new digits. In year 3, they add the digit 3, in year 4, the digit 4 etc. \n",
    "You did not retrain your model since year 2. Let's see how well it performs over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years=np.arange(2,10)\n",
    "\n",
    "Accuracy=[]\n",
    "\n",
    "for year in years :\n",
    "\n",
    "    # The people of Driftistan learn one new digit every year\n",
    "    max_digit=year\n",
    "\n",
    "    indices=np.where(test_y<max_digit+1)\n",
    "    test=test_X[indices]/256\n",
    "    test=test.reshape((test.shape[0],test.shape[1]*test.shape[2]))\n",
    "    true_y=test_y[indices]\n",
    "    \n",
    "    # Every label that is not 1 is changed to 0\n",
    "    true_y[true_y!=1]=0\n",
    "\n",
    "    test_indices=np.random.choice(test.shape[0], test_size, replace=False)\n",
    "\n",
    "    test=test[test_indices]\n",
    "    true_y=true_y[test_indices]\n",
    "\n",
    "    pred_y=clf.predict(test)\n",
    "    accuracy=accuracy_score(true_y, pred_y)\n",
    "    Accuracy=Accuracy+[accuracy]\n",
    "    print(f\"accuracy on year {year} is : {accuracy}\")\n",
    "\n",
    "figure = px.line({'year':years,'accuracy':Accuracy}, x='year', y='accuracy', title=\"Decline of accuracy over time\")\n",
    "figure.show()\n",
    "# If this does not work, uncomment this following line\n",
    "# figure.write_html(\"my_plot.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1.1 : Why is the accuracy declining over time ?\n",
    "\n",
    "Question 1.2 : What kind of drift can you see here ? Concept drift or data drift ? Please thoroughly justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To further analyse this drift, you can calculate the difference between the distribution of the new test data and the distribution of the training data. Here, the Kolmogorov-Smirnov test is used on a reduced version of the MNIST dataset. The k-s test is a statistical test to determine whether 2 data samples originate from the same dimension. Unfortunately, the k-s test works on one dimensional data. Therefore, the image data is reduced to 4 dimensions using PCA, then the k-s test is run for each dimension and the mean of the resulted stats for each dimension is returned. The rejection threshold is set arbitrarily at 8%. If the statistic is above 8%, we can reject the hypothesis that the 2 samples come from the same distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years=np.arange(2,10)\n",
    "\n",
    "n_components=4\n",
    "# if the test result average is above this number, then the samples are probably not from the same distribution\n",
    "rejection_threshold=0.08\n",
    "\n",
    "Test=[]\n",
    "\n",
    "for year in years :\n",
    "\n",
    "    max_digit=year\n",
    "\n",
    "    indices=np.where(test_y<max_digit+1)\n",
    "    test=test_X[indices]/256\n",
    "    test=test.reshape((test.shape[0],test.shape[1]*test.shape[2]))\n",
    "    true_y=test_y[indices]\n",
    "    true_y[true_y!=1]=0\n",
    "\n",
    "    test_indices=np.random.choice(test.shape[0], test_size, replace=False)\n",
    "\n",
    "    test=test[test_indices]\n",
    "    pca = PCA(n_components=n_components)\n",
    "\n",
    "    combined_data=np.vstack([X, test])\n",
    "    transformed_data = pca.fit_transform(combined_data)\n",
    "\n",
    "    X_reduced=transformed_data[:X.shape[0]]\n",
    "    test_reduced=transformed_data[X.shape[0]:]\n",
    "\n",
    "    mean_ks_stat=0\n",
    "\n",
    "    for i in range(n_components):\n",
    "        ks_stat, p_value = ks_2samp(X_reduced[:,i], test_reduced[:,i])\n",
    "        mean_ks_stat=mean_ks_stat+ks_stat\n",
    "\n",
    "    mean_ks_stat=mean_ks_stat/n_components\n",
    "\n",
    "    Test=Test+[mean_ks_stat]\n",
    "\n",
    "figure = px.line({'year':years,'k-s test':Test, \"threshold\":rejection_threshold}, x='year', y='k-s test', title=\"k-s of test data versus train data\")\n",
    "figure.add_trace(go.Scatter(x=years,y=rejection_threshold*np.ones(years.shape[0]), name = \"Rejection threshold\"))\n",
    "\n",
    "figure.show()\n",
    "# If this does not work, uncomment this following line\n",
    "# figure.write_html(\"my_plot.html\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1.3 : Interpret this graph. How does the progression of the k-s test data indicate the presence of drift?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Senario 2: Movie reviews\n",
    "\n",
    "The people of Driftistan occasionally enjoy watching movies. This year is once again year 2.  A large film studio has gathered online reviews and would like you to create a model that determines whether a review for their recent movie \"Fast and Curious : ENSTA Drift\" is positive or negative. For this, we import a labeled dataset of movie reviews. The reviews labeled 1 are positive, the reviews labeled 0 are negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{sys.executable} -m pip install gensim nltk  sentence-transformers\n",
    "!{sys.executable} -m pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "splits = {'train': 'train.parquet', 'validation': 'validation.parquet', 'test': 'test.parquet'}\n",
    "train_df = pd.read_parquet(\"hf://datasets/cornell-movie-review-data/rotten_tomatoes/\" + splits[\"train\"])\n",
    "test_df=pd.read_parquet(\"hf://datasets/cornell-movie-review-data/rotten_tomatoes/\" + splits[\"test\"])\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading all-MiniLM-L6-v2 model...\")\n",
    "st_model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, you are working with natural language inputs, so the first step is to transform these inputs into vectors. For this, we will use a sentence transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "output_dir = \"./saved_sbert_model\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "st_model.save(output_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier used is once again a random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing the review database\n",
    "X=np.array([st_model.encode(text) for text in train_df[\"text\"]])\n",
    "\n",
    "y=np.array(train_df['label'])\n",
    "\n",
    "# training the classifier\n",
    "clf = RandomForestClassifier(max_depth=2)\n",
    "clf.fit(X, y)\n",
    "\n",
    "# This will take some time, about 3-4 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size=1000\n",
    "test_indices=np.random.choice(test_df[\"text\"].shape[0], test_size, replace=False)\n",
    "\n",
    "test=test_df.iloc[test_indices,:]\n",
    "\n",
    "# no need to preprocess the labels\n",
    "true_y=test['label']\n",
    "\n",
    "test=np.array([st_model.encode(text) for text in test[\"text\"]])\n",
    "pred_y=clf.predict(test)\n",
    "accuracy=accuracy_score(true_y, pred_y)\n",
    "print(\"baseline accuracy is \",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In year 3, a mysterious wizard teaches sarcasm to a handful of Driftistan citizens. Therefore, some new reviews for \"Fast and Curious: ENSTA Drift\" are sarcastic. Over time, an increasing proportion of reviews will become sarcastic. We simulate this change by taking a portion of reviews and switching their labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the sarcasm rate is 0 on year 2, 0.05 on year 3 and increases by 0.01 every year after that\n",
    "initial_sarcasm_rate=0.05\n",
    "yearly_sarcasm_increase=0.01\n",
    "\n",
    "yearly_reviews=200\n",
    "first_year=2\n",
    "\n",
    "# The test data will be split into n equally large subsets,\n",
    "# n depends on the size of the test df and the number of reviews per year\n",
    "number_of_years=np.floor(test_df.shape[0]/yearly_reviews)\n",
    "years=np.arange(first_year,first_year+number_of_years)\n",
    "\n",
    "# a random shuffle of the df\n",
    "test_df = test_df.sample(frac = 1)\n",
    "\n",
    "\n",
    "year=first_year\n",
    "first_review=0\n",
    "sarcasm_rate=initial_sarcasm_rate\n",
    "Accuracy=[]\n",
    "\n",
    "for year in years:\n",
    "\n",
    "    # We take non overlapping subsets of the dataset every year\n",
    "    df=test_df.iloc[first_review:first_review+yearly_reviews,:]\n",
    "\n",
    "    if year>first_year:\n",
    "        \n",
    "        # switching some labels\n",
    "        sarcastic_indexes=df.sample(frac=sarcasm_rate).index\n",
    "        df.loc[sarcastic_indexes,'label']=1-df.loc[sarcastic_indexes,'label']\n",
    "        sarcasm_rate=sarcasm_rate+yearly_sarcasm_increase\n",
    "\n",
    "    true_y=np.array(df['label'])\n",
    "\n",
    "    test=np.array([st_model.encode(text) for text in df[\"text\"]])\n",
    "    pred_y=clf.predict(test)\n",
    "    accuracy=accuracy_score(true_y, pred_y)\n",
    "    print(\"Accuracy for year \",int(year),\" is \",accuracy)\n",
    "    Accuracy=Accuracy+[accuracy]\n",
    "    \n",
    "        \n",
    "figure = px.line({'year':years,'accuracy':Accuracy}, x='year', y='accuracy', title=\"Decline of accuracy over time\")\n",
    "figure.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2.1 : Why is the accuracy declining over time ?\n",
    "\n",
    "Question 2.2 : What kind of drift can you see here ? Concept drift or data drift ? Please thoroughly justify your answer.\n",
    "\n",
    "Question 2.3 : What would be the result of a k-s test in this case ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "\n",
    "Now that the drift is identified, the next step is to put in place a pipeline to prevent the model from becoming obsolete. This can be done through Continous Training. In this case, one approach could be to re-evaluate the accuracy of the models at a regular frequency (maybe every month), and if the accuracy goes below an acceptable threshold, retrain the model with current data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
