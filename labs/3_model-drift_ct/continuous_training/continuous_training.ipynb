{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Continuous Training in Machine Learning with Azure MLOps: Wine Quality Dataset\r\n",
    "Student Version\r\n",
    "=======================================================================\r\n",
    "\r\n",
    "COURSE: Introduction to MLOps with Azure ML <br>\r\n",
    "ASSIGNMENT: Implementing Continuous Training with Data Drift Detection <br>\r\n",
    "\r\n",
    "LEARNING OBJECTIVES: <br>\r\n",
    "- Understand the concept of continuous training in machine learning<br>\r\n",
    "- Implement data drift detection using a discriminator approach<br>\r\n",
    "- Create an end-to-end MLOps pipeline in Azure ML<br>\r\n",
    "- Practice real-world machine learning deployment techniques<br>\r\n",
    "- Apply best practices for maintaining ML models in production<br>\r\n",
    "\r\n",
    "INSTRUCTIONS:<br>\r\n",
    "- Complete all sections marked with TODO or EXERCISE<br>\r\n",
    "- Return the notebook with the cell outputs"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip install -r requirements.txt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Continuous Training in Machine Learning with Azure MLOps\n",
    "\n",
    "\n",
    "Setup and Dependencies"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.metrics import roc_curve, auc\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\r\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score, mean_squared_error, r2_score\r\n",
    "import datetime\r\n",
    "import joblib\r\n",
    "import os\r\n",
    "import json\r\n",
    "import requests\r\n",
    "from io import StringIO\r\n",
    "\r\n",
    "# Create directories for saving models and data\r\n",
    "os.makedirs(\"./models\", exist_ok=True)\r\n",
    "os.makedirs(\"./data\", exist_ok=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SECTION 1: Connecting to Azure ML Workspace\n",
    "---\n",
    "üìù EXERCISE (1 point): Create an Azure ML workspace and export its config file in this directory\n",
    "\n",
    "*N.B. : Cet exercise n'est pas n√©cessaire pour le reste du cours, mais il est pratique pour l'exercise bonus.*"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def connect_to_workspace():\r\n",
    "    \"\"\"Connect to Azure ML workspace using parameters.\"\"\"\r\n",
    "\r\n",
    "    ws = Workspace.get(\r\n",
    "       name=\"YOUR_WORKSPACE_NAME\",\r\n",
    "       subscription_id=\"YOUR_SUBSCRIPTION_ID\",\r\n",
    "       resource_group=\"YOUR_RESOURCE_GROUP\"\r\n",
    "    )\r\n",
    "\r\n",
    "# Connect to workspace\r\n",
    "ws = connect_to_workspace()\r\n",
    "ws"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SECTION 2: Loading and exploring the wine quality dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def load_wine_quality_data():\r\n",
    "    \"\"\"\r\n",
    "    Load Wine Quality dataset from UCI repository.\r\n",
    "    This demonstrates data acquisition in a production ML pipeline.\r\n",
    "    \"\"\"\r\n",
    "    # Download the data from the UCI repository\r\n",
    "    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\r\n",
    "    print(\"Attempting to download Wine Quality dataset from UCI repository...\")\r\n",
    "    response = requests.get(url)\r\n",
    "    if response.status_code == 200:\r\n",
    "        data = pd.read_csv(StringIO(response.text), sep=';')\r\n",
    "        print(\"Wine Quality dataset loaded successfully!\")\r\n",
    "        \r\n",
    "        # Save the raw data for future reference - good practice in ML pipelines\r\n",
    "        data.to_csv(\"./data/winequality-raw.csv\", index=False)\r\n",
    "    else:\r\n",
    "        raise Exception(f\"Failed to download dataset. Status code: {response.status_code}\")\r\n",
    "    \r\n",
    "    # Add timestamp to simulate real-world data collection\r\n",
    "    # This is important for time-series analysis and continuous training\r\n",
    "    current_date = datetime.datetime.now()\r\n",
    "    dates = [current_date - datetime.timedelta(days=i) for i in range(len(data))]\r\n",
    "    data['timestamp'] = dates\r\n",
    "    \r\n",
    "    return data\r\n",
    "\r\n",
    "# Load the dataset\r\n",
    "wine_data = load_wine_quality_data()\r\n",
    "wine_data['good_quality'] = (wine_data['quality'] >= 6).astype(int)\r\n",
    "\r\n",
    "\r\n",
    "print(f\"Wine Quality dataset shape: {wine_data.shape}\")\r\n",
    "\r\n",
    "# Display the first few rows and dataset info\r\n",
    "print(\"\\nFirst 5 rows of the dataset:\")\r\n",
    "print(wine_data.head())\r\n",
    "\r\n",
    "print(\"\\nDataset information:\")\r\n",
    "print(wine_data.info())\r\n",
    "\r\n",
    "print(\"\\nSummary statistics:\")\r\n",
    "print(wine_data.describe())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We are now creating a  visualization to explore the distribution of wine quality"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.figure(figsize=(10, 6))\r\n",
    "sns.histplot(wine_data['quality'], kde=True, discrete = True)\r\n",
    "plt.title('Distribution of Wine Quality')\r\n",
    "plt.xlabel('Quality Score')\r\n",
    "plt.ylabel('Count')\r\n",
    "plt.axvline(x=5.5, color='red', linestyle='--', label='Good Quality Threshold')\r\n",
    "plt.legend()\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see the data is well balanced between \"good\" and \"bad\" wines <br>\n",
    "Let's create a correlation matrix heatmap to explore relationships <br>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# We dont need the quality anymore \r\n",
    "wine_data.drop(columns=['quality'], inplace=True)\r\n",
    "\r\n",
    "\r\n",
    "plt.figure(figsize=(12, 8))\r\n",
    "correlation_matrix = wine_data.drop(['timestamp', 'good_quality'], axis=1).corr()\r\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\r\n",
    "plt.title('Correlation Matrix of Wine Features')\r\n",
    "plt.tight_layout()\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SECTION 3: Initial model training. <br>\n",
    "The initial model is usually called the champion model <br>\n",
    "In a real-world environnement, this would be an already registered model.pkl model in Azure. <br>\n",
    "We are training this model with original data, then the simulated new data will have some applied drift."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Prepare data for training\r\n",
    "X = wine_data.drop(['good_quality', 'timestamp'], axis=1)\r\n",
    "y = wine_data['good_quality']  # Using the binary classification target\r\n",
    "\r\n",
    "# Split data for training and testing\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\r\n",
    "\r\n",
    "def train_model(X_train, y_train, **kwargs):\r\n",
    "    \"\"\"\r\n",
    "    Train a model on the given data.\r\n",
    "    \r\n",
    "    Args:\r\n",
    "        X_train: Training features\r\n",
    "        y_train: Training target    \r\n",
    "    Returns:\r\n",
    "        Trained model object\r\n",
    "    \"\"\"\r\n",
    "    \r\n",
    "    model = RandomForestClassifier(random_state=42, **kwargs)\r\n",
    "    \r\n",
    "    # Fit the model on training data\r\n",
    "    model.fit(X_train, y_train)\r\n",
    "    print(\"Model training complete!\")\r\n",
    "    \r\n",
    "    return model\r\n",
    "\r\n",
    "def evaluate_classifier(model, X_test, y_test):\r\n",
    "    \"\"\"Evaluate a classification model and return performance metrics.\"\"\"\r\n",
    "    # Get probability predictions\r\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\r\n",
    "    \r\n",
    "    # Calculate AUC-ROC - good for imbalanced classification\r\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\r\n",
    "    \r\n",
    "    # Calculate accuracy - simple but can be misleading for imbalanced data\r\n",
    "    y_pred = model.predict(X_test)\r\n",
    "    accuracy = accuracy_score(y_test, y_pred)\r\n",
    "    \r\n",
    "    print(f\"Model AUC-ROC: {auc:.4f}\")\r\n",
    "    print(f\"Model Accuracy: {accuracy:.4f}\")\r\n",
    "    \r\n",
    "    return auc, accuracy\r\n",
    "\r\n",
    "\r\n",
    "initial_model = train_model(X_train, y_train, n_estimators=100)\r\n",
    "initial_auc, initial_accuracy = evaluate_classifier(initial_model, X_test, y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Take notes of the current model's performance. It will be important when compared to drifted data.\n",
    "\n",
    "Let's view what are the most important features for this model."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "feature_importance = pd.DataFrame({\r\n",
    "    'Feature': X_train.columns,\r\n",
    "    'Importance': initial_model.feature_importances_\r\n",
    "}).sort_values('Importance', ascending=False)\r\n",
    "\r\n",
    "plt.figure(figsize=(10, 6))\r\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importance)\r\n",
    "plt.title('Feature Importance for Wine Quality Prediction')\r\n",
    "plt.tight_layout()\r\n",
    "plt.show()\r\n",
    "\r\n",
    "print(\"\\nTop 5 most important features:\")\r\n",
    "print(feature_importance.head())\r\n",
    "\r\n",
    "\r\n",
    "# Saving the initial model\r\n",
    "# In production, you would register this model in Azure ML\r\n",
    "initial_model_path = \"./models/initial_model.pkl\"\r\n",
    "joblib.dump(initial_model, initial_model_path)\r\n",
    "print(f\"Initial model saved to {initial_model_path}\")\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SECTION 4: Data drift detection using discriminator approach <br>\n",
    "This section demonstrates how to detect data drift, which is critical for continuous training <br>\n",
    "There are multiple ways to choose when to retrain : periodically (e.g. every 1 week), when model performance drops bellow a threshold, or when data drift is detected.\n",
    "\n",
    "\n",
    "We will implement here a continuous training pipeline triggered when drift is detected, with a discriminator approach. \n",
    "\n",
    "The discriminator approach is as follows : <br>\n",
    "Between two datasets, if there is drift, a second model (discriminator) should be able to tell the datasets appart. <br>\n",
    "\n",
    "Thus, the target column is not the quality of the wine, but its source : historical / new dataset. <br>\n",
    "If the discriminator has good scores, then drift is present and the model should be retrained.\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def create_drift_wine_data(original_data, drift_percentage=0.3, magnitude=0.5):\r\n",
    "    \"\"\"\r\n",
    "    Create a drifted version of the wine dataset.\r\n",
    "    \r\n",
    "    Args:\r\n",
    "        original_data: Original wine dataset\r\n",
    "        drift_percentage: Percentage of features to apply drift to\r\n",
    "        magnitude: Magnitude of the drift\r\n",
    "    \r\n",
    "    Returns:\r\n",
    "        DataFrame with drifted values\r\n",
    "    \"\"\"\r\n",
    "    drift_data = original_data.copy()\r\n",
    "    \r\n",
    "    # Select a subset of features to drift (excluding target and timestamp)\r\n",
    "    features = [col for col in drift_data.columns if col not in ['quality', 'good_quality', 'timestamp']]\r\n",
    "    num_features_to_drift = max(1, int(len(features) * drift_percentage))\r\n",
    "    features_to_drift = np.random.choice(features, num_features_to_drift, replace=False)\r\n",
    "    \r\n",
    "    # Apply drift to selected features\r\n",
    "    for feature in features_to_drift:\r\n",
    "        # Get feature statistics\r\n",
    "        mean_val = drift_data[feature].mean()\r\n",
    "        std_val = drift_data[feature].std()\r\n",
    "        \r\n",
    "        # Apply a selective reversal drift - this inverts the relationship \r\n",
    "        # between feature and target for more extreme values\r\n",
    "        threshold = drift_data[feature].quantile(0.6)  # Top 40% of values\r\n",
    "        mask = drift_data[feature] > threshold\r\n",
    "        \r\n",
    "        # For high values: reflect across the threshold with amplification\r\n",
    "        drift_data.loc[mask, feature] = threshold - (1.5 * magnitude) * (drift_data.loc[mask, feature] - threshold)\r\n",
    "        \r\n",
    "        # For normal values: add non-linear component\r\n",
    "        drift_data.loc[~mask, feature] = drift_data.loc[~mask, feature] + magnitude * np.square(drift_data.loc[~mask, feature] - mean_val) / std_val\r\n",
    "    \r\n",
    "    # Create a newer timestamp for the drift data\r\n",
    "    latest_date = original_data['timestamp'].max()\r\n",
    "    new_dates = [latest_date + datetime.timedelta(days=i+1) for i in range(len(drift_data))]\r\n",
    "    drift_data['timestamp'] = new_dates\r\n",
    "    \r\n",
    "    print(f\"Drift applied to features: {', '.join(features_to_drift)}\")\r\n",
    "    return drift_data\r\n",
    "\r\n",
    "# Generate drift data from a subset of the original wine data\r\n",
    "# We'll use 30% of the original data to create the drift dataset\r\n",
    "np.random.seed(42)  # For reproducibility\r\n",
    "drift_indices = np.random.choice(\r\n",
    "    wine_data.index, \r\n",
    "    size=int(0.3 * len(wine_data)), \r\n",
    "    replace=False\r\n",
    ")\r\n",
    "subset_for_drift = wine_data.loc[drift_indices].copy()\r\n",
    "drift_data = create_drift_wine_data(subset_for_drift, drift_percentage=0.4, magnitude=0.8)\r\n",
    "\r\n",
    "print(f\"New data with drift shape: {drift_data.shape}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Show at least 4 features in a 2x2 subplot grid\r\n",
    "\r\n",
    "plt.figure(figsize=(15, 10))\r\n",
    "drift_features = [col for col in drift_data.columns if col not in ['quality', 'good_quality', 'timestamp']][:4]\r\n",
    "\r\n",
    "for i, feature in enumerate(drift_features):\r\n",
    "    plt.subplot(2, 2, i+1)\r\n",
    "    sns.kdeplot(wine_data[feature], label='Original Data', fill=True, alpha=0.3)\r\n",
    "    sns.kdeplot(drift_data[feature], label='Drift Data', fill=True, alpha=0.3)\r\n",
    "    plt.title(f'Distribution of {feature}')\r\n",
    "    plt.legend()\r\n",
    "\r\n",
    "plt.tight_layout()\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# The function should label the original data as 0 and new data as 1, then combine them\r\n",
    "\r\n",
    "def prepare_discriminator_data(original_data, new_data):\r\n",
    "    \"\"\"\r\n",
    "    Prepare data for training a discriminator model to detect drift.\r\n",
    "    \r\n",
    "    Args:\r\n",
    "        original_data: Original dataset\r\n",
    "        new_data: New dataset that may have drift\r\n",
    "        \r\n",
    "    Returns:\r\n",
    "        X: Combined features from both datasets\r\n",
    "        y: Binary labels (0 for original, 1 for new)\r\n",
    "    \"\"\"\r\n",
    "    # Get features only - exclude target and timestamp\r\n",
    "    original_features = original_data.drop(['good_quality', 'timestamp'], axis=1)\r\n",
    "    new_features = new_data.drop(['good_quality', 'timestamp'], axis=1)\r\n",
    "    \r\n",
    "    # Label the data sources: 0 for original, 1 for new\r\n",
    "    original_features['source'] = 0\r\n",
    "    new_features['source'] = 1\r\n",
    "    \r\n",
    "    # Combine the datasets\r\n",
    "    combined_data = pd.concat([original_features, new_features], axis=0)\r\n",
    "    \r\n",
    "    # Shuffle the data for better training\r\n",
    "    combined_data = combined_data.sample(frac=1, random_state=42).reset_index(drop=True)\r\n",
    "    \r\n",
    "    # Split features and label\r\n",
    "    X = combined_data.drop('source', axis=1)\r\n",
    "    y = combined_data['source']\r\n",
    "    \r\n",
    "    return X, y\r\n",
    "\r\n",
    "# Prepare data for the discriminator\r\n",
    "X_disc, y_disc = prepare_discriminator_data(wine_data, drift_data)\r\n",
    "X_disc_train, X_disc_test, y_disc_train, y_disc_test = train_test_split(X_disc, y_disc, test_size=0.2, random_state=42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Train the discriminator model\r\n",
    "discriminator_model = RandomForestClassifier(n_estimators=\"A REMPLIR\", random_state=42)\r\n",
    "discriminator_model.fit(X_disc_train, y_disc_train)\r\n",
    "\r\n",
    "# Evaluate the discriminator\r\n",
    "y_disc_pred_proba = discriminator_model.predict_proba(X_disc_test)[:, 1]\r\n",
    "discriminator_auc = roc_auc_score(y_disc_test, y_disc_pred_proba)\r\n",
    "print(f\"Discriminator AUC-ROC: {discriminator_auc:.4f}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see it is **extremely easy** for the model to discriminate between the two datasets. It means our discriminator can easily guess where the data comes from. If the data was undrifted, the discriminator wouldnt be able to guess its source <br>\n",
    "\n",
    "In a real world scenario, the AUC-ROC metric can be used as a trigger to retrain a model."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SECTION 5: Continuous Training Decision Logic <br>\n",
    "We will now start to build brick by brick the continuous machine learning pipeline.\n",
    "\n",
    "We first need a quick function to decide wether retraining is needed or not."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def should_retrain(discriminator_auc, threshold=0.7):\r\n",
    "    \"\"\"\r\n",
    "    Decide if retraining is needed based on the discriminator's ability to distinguish data sources.\r\n",
    "    \r\n",
    "    Args:\r\n",
    "        discriminator_auc: AUC-ROC score of the discriminator model\r\n",
    "        threshold: Threshold above which we consider significant drift detected\r\n",
    "        \r\n",
    "    Returns:\r\n",
    "        bool: True if retraining is recommended\r\n",
    "    \"\"\"\r\n",
    "    if discriminator_auc >= threshold:\r\n",
    "        print(f\"Significant data drift detected (AUC = {discriminator_auc:.4f} > {threshold}).\")\r\n",
    "        print(\"Recommendation: Retrain the model with new data.\")\r\n",
    "        return True\r\n",
    "    else:\r\n",
    "        print(f\"No significant data drift detected (AUC = {discriminator_auc:.4f} <= {threshold}).\")\r\n",
    "        print(\"Recommendation: Continue using the current model.\")\r\n",
    "        return False\r\n",
    "\r\n",
    "# Check if retraining is recommended based on the discriminator performance\r\n",
    "# retrain_recommended = should_retrain(discriminator_auc, threshold=0.7)\r\n",
    "\r\n",
    "# For teaching purposes, let's assume a high discriminator AUC (simulating drift)\r\n",
    "# In reality, this value would come from the actual discriminator model\r\n",
    "retrain_recommended = should_retrain(discriminator_auc, threshold=0.7)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "When data drift is detected, a proper workflow would track the drift. Here, we have a discriminator mode. To track where the drift comes from, we could simply look at what features were the most important to the discirminator model. If a feature is extremely important for the discriminator, data drift occured there."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create a visualization of the features that show the most drift according to the discriminator\r\n",
    "\r\n",
    "disc_feature_importance = pd.DataFrame({\r\n",
    "    'Feature': X_disc.columns,\r\n",
    "    'Importance': discriminator_model.feature_importances_\r\n",
    "}).sort_values('Importance', ascending=False)\r\n",
    "\r\n",
    "plt.figure(figsize=(10, 6))\r\n",
    "sns.barplot(x='Importance', y='Feature', data=disc_feature_importance)\r\n",
    "plt.title('Feature Importance for Drift Detection')\r\n",
    "plt.tight_layout()\r\n",
    "plt.show()\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\nTop features that show the most drift:\")\r\n",
    "print(disc_feature_importance.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see the important features for the discriminator are the ones we applied a drift to :  `pH, alcohol, sulphates, chlorides` "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SECTION 6: Model Retraining <br>\r\n",
    "If drift is detected, we retrain the model with combined data <br>\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Retrain the model when drift is detected\r\n",
    "# The model should be trained on both original and new data\r\n",
    "\r\n",
    "if retrain_recommended:\r\n",
    "    # Using only the drifted data for retraining\r\n",
    "    X_drifted = drift_data.drop(['good_quality', 'timestamp'], axis=1)\r\n",
    "    y_drifted = drift_data['good_quality']\r\n",
    "    \r\n",
    "    # Prepare for retraining\r\n",
    "    X_drift_train, X_drift_test, y_drift_train, y_drift_test = train_test_split(\r\n",
    "        X_drifted, y_drifted, test_size=0.2, random_state=42\r\n",
    "    )\r\n",
    "    \r\n",
    "    # Retrain the model on only the drifted data\r\n",
    "    retrained_model = train_model(X_drift_train, y_drift_train, n_estimators=100)\r\n",
    "    print(\"Model retrained with drifted data only!\")\r\n",
    "    \r\n",
    "    # Evaluate the retrained model on drifted test data\r\n",
    "    y_retrain_pred_proba = retrained_model.predict_proba(X_drift_test)[:, 1]\r\n",
    "    retrained_auc = roc_auc_score(y_drift_test, y_retrain_pred_proba)\r\n",
    "    print(f\"Retrained model AUC-ROC on drift test data: {retrained_auc:.4f}\")\r\n",
    "    \r\n",
    "    # Compare with original model on the new test data\r\n",
    "    original_on_drift_auc = roc_auc_score(\r\n",
    "        y_drift_test, \r\n",
    "        initial_model.predict_proba(X_drift_test)[:, 1]\r\n",
    "    )\r\n",
    "    print(f\"Original model AUC-ROC on drift test data: {original_on_drift_auc:.4f}\")\r\n",
    "    \r\n",
    "    # Visualization of model comparison\r\n",
    "    plt.figure(figsize=(8, 6))\r\n",
    "    \r\n",
    "    # Calculate ROC curve for both models\r\n",
    "    fpr_original, tpr_original, _ = roc_curve(y_drift_test, initial_model.predict_proba(X_drift_test)[:, 1])\r\n",
    "    fpr_retrained, tpr_retrained, _ = roc_curve(y_drift_test, y_retrain_pred_proba)\r\n",
    "    \r\n",
    "    # Plot ROC curves\r\n",
    "    plt.plot(fpr_original, tpr_original, label=f'Original Model (AUC = {original_on_drift_auc:.4f})')\r\n",
    "    plt.plot(fpr_retrained, tpr_retrained, label=f'Retrained Model (AUC = {retrained_auc:.4f})')\r\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\r\n",
    "    plt.xlabel('False Positive Rate')\r\n",
    "    plt.ylabel('True Positive Rate')\r\n",
    "    plt.title('ROC Curve Comparison: Original vs Retrained Model')\r\n",
    "    plt.legend()\r\n",
    "    plt.show()\r\n",
    "    \r\n",
    "    # Save the retrained model\r\n",
    "    retrained_model_path = \"./models/retrained_model.pkl\"\r\n",
    "    joblib.dump(retrained_model, retrained_model_path)\r\n",
    "    \r\n",
    "    print(\"Model retraining completed!\")\r\n",
    "\r\n",
    "else:\r\n",
    "    print(\"No retraining needed. The current model is still valid.\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we can see the retraining was justified on the drifted data. Theold model was performing very poorly on the drifted dataset. \n",
    "\n",
    "--- \n",
    "\n",
    "üìù EXERCISE (1 point): Why shouldn't we use all combined data ? How may it be a problem for the model's performance. In ~ 50 words\n",
    "\n",
    "ANSWER : Using all data means learning on values that are not up to date if the drift is permanent. The learned feature interactions of old data is now noise to the model. But learning only on drifted data means learning on a smaller dataset, impacting the model's performance."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SECTION 7: Azure ML Pipeline for Continuous Training\r\n",
    "\r\n",
    "### **Pipeline Overview**  \r\n",
    "This pipeline automates detecting changes in data patterns (drift) and retraining our model if needed, then registering it as the new production model. It can be scheduled to run every week, for instance. Let's assume we have a data stream that updates every week the current and historical data.\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "It uses **three inputs**:  \r\n",
    "- `model.pkl` (a pre-trained model from Azure)  \r\n",
    "- `current_data.csv` (new data to analyze)  \r\n",
    "- `historical_data.csv` (past data for comparison)  \r\n",
    "\r\n",
    "\r\n",
    "It produces **two outputs**:  \r\n",
    "- Updated `model.pkl` (if retraining occurs)  \r\n",
    "- A `json` file indicating whether drift was detected .  \r\n",
    "\r\n",
    "### **Step-by-Step Workflow**  \r\n",
    "You will see in the `components` subfolder the different components to add to Azure ML Designer. They are based on the previous work.\r\n",
    "1. **Data Preparation**  \r\n",
    "   - Clean and format `historical_data.csv` by removing the `quality` column. \r\n",
    "\r\n",
    "2. **Drift Detection**  \r\n",
    "   - This step compares `current_data.csv` with `historical_data.csv` to check if significant differences exist, with the help of a discriminator model. If drift is found (`drift_detected = True`), the model will not be registered.\r\n",
    "\r\n",
    "3. **Model Training**  \r\n",
    "   - If drift is detected, train a new model using the updated data. This step ensures the model adapts to new patterns in the data\r\n",
    "   - This step is done in parallel to drift detection in order to save overall time, but a proper workflow would only train the model if drift was detected.\r\n",
    "\r\n",
    "4. **Registering Model (if drift was detected)**  \r\n",
    "   - If drift was detected, save the newly trained model (`model.pkl`) to Azure as the latest version. This makes it available for future deployments or pipelines.\r\n",
    "   - The registered model.pkl will be in the blob storage.\r\n",
    "\r\n",
    "--- \r\n",
    "\r\n",
    "üìù EXERCISE (2 points): Create Azure ML Components via Web Interface\r\n",
    "\r\n",
    "TODO: Follow these steps in the Azure ML Studio web interface:\r\n",
    "\r\n",
    "1. Create a new Dataset:\r\n",
    "   - Go to 'Assets' > 'Datasets' > 'Create dataset'\r\n",
    "   - Upload winequality-raw.csv from your local files\r\n",
    "   - Name it 'wine_quality_training_data'\r\n",
    "   - Create a second dataset with drifted_data.csv\r\n",
    "2. Create Compute Target:\r\n",
    "   - Go to 'Manage' > 'Compute' > 'Compute clusters' > 'New'\r\n",
    "   - Create CPU cluster named 'training-cluster' with:\r\n",
    "     - VM size: Standard_DS3_v2\r\n",
    "     - Minimum 0, maximum 2 nodes\r\n",
    "     - Idle seconds before scale down: 120\r\n",
    "     - Wait a few minutes\r\n",
    "3. Create Pipeline Components:\r\n",
    "   - Go to 'Assets' > 'Components' > 'Create new'\r\n",
    "   - Create these components through the UI:\r\n",
    "     - data_preparation Component\r\n",
    "     - drift_detection Component\r\n",
    "     - model_training Component\r\n",
    "     - model_registration Component"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "--- \n",
    "üìù EXERCISE (2 points): Configure Pipeline via Web Interface\n",
    "TODO: Create pipeline using drag-and-drop interface\n",
    "1. Go to 'Authoring' > 'Designer' > Create a pipeline using custom components\n",
    "2. Drag in the 4 created components. (Note : The drifted data shouldnt be prepared, it already has the \"good_quality\" column.)\n",
    "3. Connect them in sequence\n",
    "4. Configure schedule:\n",
    "   - Set to run weekly using trigger configuration\n",
    "   - Enable email notifications for pipeline failures\n",
    "5. Publish pipeline as 'wine_quality_ct_pipeline'"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "--- \n",
    "üìù BONUS EXERCISE (1 point): Launch this pipeline using azure cli and paste the lines here\n",
    "\n",
    "You will need to create a pipeline.yaml file describing the different step you have done in the UI"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "QUESTIONS :"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Question 1: Expliquez le concept de \"continuous training\" en Machine Learning et pourquoi il est essentiel dans un environnement de production. Donnez au moins 3 raisons principales.\r\n",
    "\r\n",
    "Question 2: Qu'est-ce que le data drift et comment peut-il affecter les performances d'un mod√®le de machine learning en production ? Illustrez avec un exemple concret du domaine viticole.\r\n",
    "\r\n",
    "Question 3: D√©crivez en d√©tail l'approche discriminateur pour d√©tecter le data drift. Comment fonctionne cette m√©thode et que signifie un AUC-ROC √©lev√© (>0.7) pour le mod√®le discriminateur ?\r\n",
    "\r\n",
    "Question 4: Dans le TP, le discriminateur obtient un AUC-ROC tr√®s √©lev√©. Analysez ce r√©sultat : qu'est-ce que cela indique sur la qualit√© des donn√©es ? Quel seuil d'AUC-ROC recommanderiez-vous pour d√©clencher un r√©entra√Ænement ?\r\n",
    "\r\n",
    "Question 5: Quels sont les avantages de cr√©er des composants r√©utilisables dans Azure ML Designer par rapport √† un script monolithique ? Donnez au moins 4 avantages pratiques pour une √©quipe de data scientists."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}